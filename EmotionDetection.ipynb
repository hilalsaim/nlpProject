{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\51588\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\51588\\anaconda3\\lib\\site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: click in c:\\users\\51588\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\users\\51588\\anaconda3\\lib\\site-packages (from nltk) (2020.10.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\51588\\anaconda3\\lib\\site-packages (from nltk) (4.62.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\51588\\anaconda3\\lib\\site-packages (from tqdm->nltk) (0.4.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\51588\\anaconda3\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already up-to-date: textblob in c:\\users\\51588\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied, skipping upgrade: nltk>=3.1; python_version >= \"3\" in c:\\users\\51588\\anaconda3\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied, skipping upgrade: joblib in c:\\users\\51588\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (0.17.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in c:\\users\\51588\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (4.62.0)\n",
      "Requirement already satisfied, skipping upgrade: click in c:\\users\\51588\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: regex in c:\\users\\51588\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (2020.10.15)\n",
      "Requirement already satisfied, skipping upgrade: colorama; platform_system == \"Windows\" in c:\\users\\51588\\anaconda3\\lib\\site-packages (from tqdm->nltk>=3.1; python_version >= \"3\"->textblob) (0.4.4)\n",
      "Requirement already satisfied: advertools in c:\\users\\51588\\anaconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\51588\\anaconda3\\lib\\site-packages (from advertools) (1.1.3)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from advertools) (0.4.8)\n",
      "Requirement already satisfied: twython in c:\\users\\51588\\anaconda3\\lib\\site-packages (from advertools) (3.9.1)\n",
      "Requirement already satisfied: scrapy in c:\\users\\51588\\anaconda3\\lib\\site-packages (from advertools) (2.6.1)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\51588\\anaconda3\\lib\\site-packages (from advertools) (8.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from pandas->advertools) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from pandas->advertools) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from pandas->advertools) (1.21.5)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from twython->advertools) (2.27.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.4.0 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from twython->advertools) (1.3.0)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from scrapy->advertools) (0.5.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\51588\\anaconda3\\lib\\site-packages (from scrapy->advertools) (50.3.1.post20201107)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from scrapy->advertools) (1.1.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from scrapy->advertools) (1.0.4)\n",
      "Requirement already satisfied: service-identity>=16.0.0 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from scrapy->advertools) (21.1.0)\n",
      "Requirement already satisfied: lxml>=3.5.0; platform_python_implementation == \"CPython\" in c:\\users\\51588\\anaconda3\\lib\\site-packages (from scrapy->advertools) (4.6.1)\n",
      "Requirement already satisfied: pyOpenSSL>=16.2.0 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from scrapy->advertools) (19.1.0)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5; platform_python_implementation == \"CPython\" in c:\\users\\51588\\anaconda3\\lib\\site-packages (from scrapy->advertools) (2.0.5)\n",
      "Requirement already satisfied: zope.interface>=4.1.3 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from scrapy->advertools) (5.1.2)\n",
      "Requirement already satisfied: cryptography>=2.0 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from scrapy->advertools) (3.1.1)\n",
      "Requirement already satisfied: Twisted>=17.9.0 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from scrapy->advertools) (22.4.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from scrapy->advertools) (1.6.2)\n",
      "Requirement already satisfied: parsel>=1.5.0 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from scrapy->advertools) (1.6.0)\n",
      "Requirement already satisfied: tldextract in c:\\users\\51588\\anaconda3\\lib\\site-packages (from scrapy->advertools) (3.3.0)\n",
      "Requirement already satisfied: protego>=0.1.15 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from scrapy->advertools) (0.2.1)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from scrapy->advertools) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->advertools) (1.15.0)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in c:\\users\\51588\\anaconda3\\lib\\site-packages (from requests>=2.1.0->twython->advertools) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from requests>=2.1.0->twython->advertools) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from requests>=2.1.0->twython->advertools) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in c:\\users\\51588\\anaconda3\\lib\\site-packages (from requests>=2.1.0->twython->advertools) (2.0.12)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.4.0->twython->advertools) (3.2.0)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from itemloaders>=1.0.1->scrapy->advertools) (1.0.0)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\51588\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy->advertools) (0.2.8)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy->advertools) (20.3.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from cryptography>=2.0->scrapy->advertools) (1.14.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy->advertools) (3.7.4.3)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy->advertools) (21.0.0)\n",
      "Requirement already satisfied: incremental>=21.3.0 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy->advertools) (21.3.0)\n",
      "Requirement already satisfied: twisted-iocpsupport<2,>=1.0.2; platform_system == \"Windows\" in c:\\users\\51588\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy->advertools) (1.0.2)\n",
      "Requirement already satisfied: Automat>=0.8.0 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy->advertools) (20.2.0)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy->advertools) (15.1.0)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from tldextract->scrapy->advertools) (3.0.12)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\51588\\anaconda3\\lib\\site-packages (from tldextract->scrapy->advertools) (1.5.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\51588\\anaconda3\\lib\\site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.0->scrapy->advertools) (2.20)\n"
     ]
    }
   ],
   "source": [
    "# install necessary libs\n",
    "!pip install nltk\n",
    "!pip install pandas\n",
    "!pip install -U textblob\n",
    "!pip install advertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re # for regular expressions\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from textblob import TextBlob\n",
    "import advertools as adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @TimothyDSnyder: It is senseless to shelter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@chaplinez70 Murderous Putin, over to you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @EmbassyofRussia: ðŸ‡·ðŸ‡ºPresident #Putin on US ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @AnonOpsSE: Putin's propagandist Vladimir S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @co_co_no5: @OnlinePalEng I think these Isr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56957</th>\n",
       "      <td>RT @yarotrof: They built monuments to Grandma ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56958</th>\n",
       "      <td>@BorisJohnson @CMShehbaz Mr Putin is an evil m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56959</th>\n",
       "      <td>RT @McFaul: Those arguing against weapons tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56960</th>\n",
       "      <td>RT @GlasnostGone: Illustrating peace talks wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56961</th>\n",
       "      <td>RT @GeorgeSzamuely: The lack of journalistic c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56962 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0      RT @TimothyDSnyder: It is senseless to shelter...\n",
       "1              @chaplinez70 Murderous Putin, over to you\n",
       "2      RT @EmbassyofRussia: ðŸ‡·ðŸ‡ºPresident #Putin on US ...\n",
       "3      RT @AnonOpsSE: Putin's propagandist Vladimir S...\n",
       "4      RT @co_co_no5: @OnlinePalEng I think these Isr...\n",
       "...                                                  ...\n",
       "56957  RT @yarotrof: They built monuments to Grandma ...\n",
       "56958  @BorisJohnson @CMShehbaz Mr Putin is an evil m...\n",
       "56959  RT @McFaul: Those arguing against weapons tran...\n",
       "56960  RT @GlasnostGone: Illustrating peace talks wit...\n",
       "56961  RT @GeorgeSzamuely: The lack of journalistic c...\n",
       "\n",
       "[56962 rows x 1 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read tweets from csv file\n",
    "tweets = pd.read_csv('./data/Putin.csv')\n",
    "tweets = tweets.rename(columns={'0': 'text'})\n",
    "tweets.head()\n",
    "tweets.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from Lexicon import lexicon\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "tqdm.pandas()\n",
    "\n",
    "emoji_lexicon = pd.read_csv('resource_folder/EmoTag1200-scores.csv', sep =',')\n",
    "emoji_dict = emoji_lexicon.set_index('emoji').T.to_dict()\n",
    "emoji_factor = 0.1\n",
    "\n",
    "# extention of NRCLex, rewrite build_word_affect mehtod to add emoji analysis\n",
    "class NRCLexEx():\n",
    "    def build_word_affect(self):\n",
    "        #print('build_word_affect')\n",
    "        # Build word affect function\n",
    "        affect_list = []\n",
    "        affect_dict = dict()\n",
    "        affect_frequencies = Counter()\n",
    "        lexicon_keys = lexicon.keys()\n",
    "        for word in self.words:\n",
    "            if word in lexicon_keys:\n",
    "                affect_list.extend(lexicon[word])\n",
    "                affect_dict.update({word: lexicon[word]})\n",
    "        for word in affect_list:\n",
    "            affect_frequencies[word] += 1\n",
    "        sum_values = sum(affect_frequencies.values())\n",
    "        affect_percent = {'fear': 0.0, 'anger': 0.0, 'anticipation': 0.0, 'trust': 0.0, 'surprise': 0.0, 'sadness': 0.0, 'disgust': 0.0, 'joy': 0.0}\n",
    "        emoji_affect_percent = {'fear': 0.0, 'anger': 0.0, 'anticipation': 0.0, 'trust': 0.0, 'surprise': 0.0, 'sadness': 0.0, 'disgust': 0.0, 'joy': 0.0}\n",
    "        for key in affect_frequencies.keys():\n",
    "            affect_percent.update({key: float(affect_frequencies[key]) / float(sum_values)})\n",
    "\n",
    "        emoji_affect_frequencies = Counter()\n",
    "        if len(affect_list) > 0:\n",
    "            for emoji in self.emojis:\n",
    "                #print(emoji)\n",
    "                if emoji in emoji_dict.keys():\n",
    "                    emoji_affect_dic = emoji_dict[emoji]\n",
    "                    #print(emoji_affect_frequencies)\n",
    "                    for key in affect_percent.keys():\n",
    "                        if emoji_affect_dic[key] > 0:\n",
    "                            emoji_affect_frequencies[key] += emoji_affect_dic[key]\n",
    "        emoji_sum_values = sum(emoji_affect_frequencies.values())\n",
    "        #print('emoji_sum_values',emoji_sum_values)\n",
    "        #print('emoji_affect_frequencies',emoji_affect_frequencies)\n",
    "        for key in emoji_affect_frequencies.keys():\n",
    "            #print(float(emoji_affect_frequencies[key]),float(emoji_sum_values),float(emoji_affect_frequencies[key]) / float(emoji_sum_values))\n",
    "            #freq = float(emoji_affect_frequencies[key]) / float(emoji_sum_values)\n",
    "            #print(freq)\n",
    "            emoji_affect_percent.update({key: float(emoji_affect_frequencies[key]) / float(emoji_sum_values)})\n",
    "            #print(key,'emoji_affect_frequencies',emoji_affect_frequencies)\n",
    "        self.affect_list = affect_list\n",
    "        self.raw_emotion_scores = dict(affect_frequencies)\n",
    "        self.affect_frequencies = affect_percent\n",
    "        self.emoji_affect_frequencies = emoji_affect_percent\n",
    "\n",
    "    def __init__(self,text,emojis):\n",
    "        self.text = text\n",
    "        blob = TextBlob(text)\n",
    "        self.words = list(blob.words)\n",
    "        self.sentences = list(blob.sentences)\n",
    "        self.emojis = emojis\n",
    "        self.build_word_affect()\n",
    "        self.top_emotions()\n",
    "\n",
    "    # get top emotins based on accumulate score\n",
    "    def top_emotions(self):\n",
    "        emo_dict = self.affect_frequencies\n",
    "        max_value = max(emo_dict.values())\n",
    "        top_emotions = []\n",
    "        for key in emo_dict.keys():\n",
    "            if emo_dict[key] == max_value and max_value > 0:\n",
    "                top_emotions.append((key, max_value))\n",
    "        self.top_emotions = top_emotions\n",
    "        emoji_emo_dict = self.emoji_affect_frequencies\n",
    "        emoji_max_value = max(emoji_emo_dict.values())\n",
    "        top_emoji_emotions = []\n",
    "        for key in emoji_emo_dict.keys():\n",
    "            if emoji_emo_dict[key] == emoji_max_value and emoji_max_value > 0:\n",
    "                top_emoji_emotions.append((key, emoji_max_value))\n",
    "        self.top_emoji_emotions = top_emoji_emotions\n",
    "\n",
    "# Test\n",
    "#text_object = NRCLexEx(\"o denote the measurements of some unknown quantity V,\"\n",
    "#                        \" and sought the  estimator of that quantity\",['ðŸŒˆ', 'ðŸ‘', 'ðŸ‘','ðŸ™„'])\n",
    "#print(text_object.affect_frequencies);\n",
    "#print(text_object.top_emotions);\n",
    "#print(text_object.top_emoji_emotions);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EmotionDetector:\n",
    "    # copyed from nrclex.py, remove positive and negative emotions\n",
    "\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    tk = TweetTokenizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "    # initialize lexicon\n",
    "    def __init__(self, emoji_factor = 1):\n",
    "        # load lexico from https://github.com/abushoeb/EmoTag for emoji emotion detection\n",
    "        self.emoji_factor = emoji_factor\n",
    "\n",
    "    def process(self, dataFrame, columnName='text'):\n",
    "        print(\"begin to extract emoji \")\n",
    "        emoji_summary = adv.extract_emoji(dataFrame[columnName])\n",
    "        dataFrame['emojis'] = emoji_summary['emoji']\n",
    "        print(\"pre process\")\n",
    "        pre_process_res= dataFrame[columnName].progress_apply(EmotionDetector.pre_process)\n",
    "        dataFrame = pd.concat([dataFrame, pre_process_res], axis=1)\n",
    "        print(\"emotion analysis\")\n",
    "        res = dataFrame.progress_apply(self.emotion_analysis,axis=1)\n",
    "        res.head()\n",
    "        dataFrame = pd.concat([dataFrame, res], axis=1)\n",
    "        print(\"sentiment analysis\")\n",
    "        sentiment_analysis_res = dataFrame.progress_apply(self.sentiment_analysis,axis=1)\n",
    "        dataFrame = pd.concat([dataFrame, sentiment_analysis_res], axis=1)\n",
    "        return dataFrame\n",
    "\n",
    "    # sentiment analysis method\n",
    "    def sentiment_analysis(self, row):\n",
    "        words = row[\"tokens\"]\n",
    "        score = EmotionDetector.analyser.polarity_scores(str(words))\n",
    "        score=score['compound']\n",
    "        res = 'Neutral'\n",
    "        if score>=0.05:\n",
    "            res = 'Positive'\n",
    "        elif score<=-0.05:\n",
    "            res = 'Negative'\n",
    "        else:\n",
    "            res = 'Neutral'\n",
    "        return pd.Series([score,res],\n",
    "                         index=['sentiment_score', 'sentiment'])\n",
    "\n",
    "    # emotion analysis method\n",
    "    def emotion_analysis(self, row):\n",
    "        #print(\"1111\")\n",
    "        #print(row)\n",
    "        text = row[\"text\"]\n",
    "        emojis = row['emojis']\n",
    "        emotions = NRCLexEx(text,emojis)\n",
    "        top_emotions = emotions.top_emotions\n",
    "        top_emoji_emotions = emotions.top_emoji_emotions\n",
    "        top_emotions_dict = {'fear': 0, 'anger': 0, 'anticipation': 0, 'trust': 0, 'surprise': 0,\n",
    "                             'sadness': 0, 'disgust': 0, 'joy': 0}\n",
    "        top_eomji_emotions_dict = {'e_fear': 0, 'e_anger': 0, 'e_anticipation': 0, 'e_trust': 0, 'e_surprise': 0,\n",
    "                             'e_sadness': 0, 'e_disgust': 0, 'e_joy': 0}\n",
    "        #print(top_emotions)\n",
    "        for key,value in top_emotions:\n",
    "            top_emotions_dict[key] = value\n",
    "        for key,value in top_emoji_emotions:\n",
    "            top_eomji_emotions_dict['e_'+key] = value\n",
    "        # print(top_emotions_dict.values())\n",
    "        # print(top_emotions_dict.keys())\n",
    "        # res = [affect_list,affect_dict,dict(affect_frequencies),affect_percent,top_emotions]\n",
    "        # res = res.append()\n",
    "        return pd.Series([top_emotions,*top_emotions_dict.values(),*top_eomji_emotions_dict.values()],\n",
    "                         index=['top_emotions',*top_emotions_dict.keys(),*top_eomji_emotions_dict.keys()])\n",
    "\n",
    "    @staticmethod\n",
    "    def pre_process(text):\n",
    "        #print(text)\n",
    "        # clean text\n",
    "        text = EmotionDetector.cleanText(str(text))\n",
    "        #print(text)\n",
    "        #emoji_summary = adv.extract_emoji([text])\n",
    "        #print(emoji_summary['emoji'])\n",
    "        #tokenization = nltk.word_tokenize(text)\n",
    "        # tokenization = EmotionDetector.tk.tokenize(text)\n",
    "\n",
    "        blob = TextBlob(text)\n",
    "        filtered_words = [word.lower() for word in blob.words]\n",
    "        nouns = []\n",
    "        adjectives = []\n",
    "        for word, tag in pos_tag(filtered_words):\n",
    "            # since most tweets contain such words, it is not helpful for future analysis\n",
    "            if word.startswith(\"russi\") or word.startswith(\"ukrai\"):\n",
    "                continue\n",
    "            if tag.startswith(\"NN\"): #Nouns\n",
    "                nouns.append(word)\n",
    "            elif tag.startswith(\"JJ\"): #Adjective\n",
    "                adjectives.append(word)\n",
    "\n",
    "        # map_object = map(EmotionDetector.stemmer.stem, filtered_words)\n",
    "        # lemma_words = list(map_object)\n",
    "        #print(lemma_words)\n",
    "        return pd.Series([' '.join(filtered_words),' '.join(nouns),' '.join(adjectives)],\n",
    "                         index=['tokens', 'nouns', 'adjectives'])\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def cleanText(text):\n",
    "        text=text.lower()\n",
    "        text = re.sub(r'(?i)RT @\\w+: ','', text) # remove RT\n",
    "        text = re.sub(r'@\\w+','', text) # remove @member\n",
    "        text = re.sub(r'#','', text) # remove # symbol\n",
    "        text = re.sub(r'https?:\\/\\/\\S+','', text) # remove the hyper link\n",
    "        text = re.sub(r'[^\\w\\s]', '', text) # remove punctuations\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-e31f1f1611e6>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataFrame['emojis'] = emoji_summary['emoji']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to extract emoji \n",
      "pre process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 178.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 609.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1086.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>tokens</th>\n",
       "      <th>nouns</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>top_emotions</th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>trust</th>\n",
       "      <th>...</th>\n",
       "      <th>e_fear</th>\n",
       "      <th>e_anger</th>\n",
       "      <th>e_anticipation</th>\n",
       "      <th>e_trust</th>\n",
       "      <th>e_surprise</th>\n",
       "      <th>e_sadness</th>\n",
       "      <th>e_disgust</th>\n",
       "      <th>e_joy</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @TimothyDSnyder: It is senseless to shelter...</td>\n",
       "      <td>[]</td>\n",
       "      <td>it is senseless to shelter putin from the sens...</td>\n",
       "      <td>putin sense</td>\n",
       "      <td>senseless</td>\n",
       "      <td>[(anger, 0.25), (sadness, 0.25)]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.3818</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@chaplinez70 Murderous Putin, over to you</td>\n",
       "      <td>[]</td>\n",
       "      <td>murderous putin over to you</td>\n",
       "      <td>putin</td>\n",
       "      <td>murderous</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.6369</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @EmbassyofRussia: ðŸ‡·ðŸ‡ºPresident #Putin on US ...</td>\n",
       "      <td>[ðŸ‡·ðŸ‡º]</td>\n",
       "      <td>president putin on us biolabs in ukraine their...</td>\n",
       "      <td>president putin task materials spread viruses</td>\n",
       "      <td>biological analyze</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @AnonOpsSE: Putin's propagandist Vladimir S...</td>\n",
       "      <td>[]</td>\n",
       "      <td>putins propagandist vladimir solovyov will nev...</td>\n",
       "      <td>putins solovyov villa shores lake como italy s...</td>\n",
       "      <td>vladimir</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @co_co_no5: @OnlinePalEng I think these Isr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>i think these israelites are definitely more b...</td>\n",
       "      <td>i israelites putin</td>\n",
       "      <td>barbaric</td>\n",
       "      <td>[(fear, 0.3333333333333333), (anger, 0.3333333...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RT @suzannelynch1: The ambassadors of #Finland...</td>\n",
       "      <td>[]</td>\n",
       "      <td>the ambassadors of finland and sweden are due ...</td>\n",
       "      <td>ambassadors finland sweden headquarters brusse...</td>\n",
       "      <td>due nato</td>\n",
       "      <td>[(anticipation, 1.0)]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>RT @TimothyDSnyder: It is senseless to create ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>it is senseless to create an offramp in the re...</td>\n",
       "      <td>offramp world putin world</td>\n",
       "      <td>senseless real virtual</td>\n",
       "      <td>[(fear, 0.14285714285714285), (anger, 0.142857...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>@longshortgamma @simonkwo2012 Pictures tell a ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>pictures tell a thousand words videos tell ten...</td>\n",
       "      <td>pictures thousand words video</td>\n",
       "      <td></td>\n",
       "      <td>[(anger, 1.0)]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>RT @maxseddon: Putin: \"Giving up Russian energ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>putin giving up russian energy resources will ...</td>\n",
       "      <td>putin energy resources region energy costs wor...</td>\n",
       "      <td>highest</td>\n",
       "      <td>[(joy, 0.3333333333333333)]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>RT @SpencerGuard: I'm proud to be listed in an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>im proud to be listed in an article calling ou...</td>\n",
       "      <td>proud article lies guy vladimir putin person</td>\n",
       "      <td>im same</td>\n",
       "      <td>[(anticipation, 0.3333333333333333), (trust, 0...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text emojis  \\\n",
       "0   RT @TimothyDSnyder: It is senseless to shelter...     []   \n",
       "1           @chaplinez70 Murderous Putin, over to you     []   \n",
       "2   RT @EmbassyofRussia: ðŸ‡·ðŸ‡ºPresident #Putin on US ...   [ðŸ‡·ðŸ‡º]   \n",
       "3   RT @AnonOpsSE: Putin's propagandist Vladimir S...     []   \n",
       "4   RT @co_co_no5: @OnlinePalEng I think these Isr...     []   \n",
       "..                                                ...    ...   \n",
       "95  RT @suzannelynch1: The ambassadors of #Finland...     []   \n",
       "96  RT @TimothyDSnyder: It is senseless to create ...     []   \n",
       "97  @longshortgamma @simonkwo2012 Pictures tell a ...     []   \n",
       "98  RT @maxseddon: Putin: \"Giving up Russian energ...     []   \n",
       "99  RT @SpencerGuard: I'm proud to be listed in an...     []   \n",
       "\n",
       "                                               tokens  \\\n",
       "0   it is senseless to shelter putin from the sens...   \n",
       "1                         murderous putin over to you   \n",
       "2   president putin on us biolabs in ukraine their...   \n",
       "3   putins propagandist vladimir solovyov will nev...   \n",
       "4   i think these israelites are definitely more b...   \n",
       "..                                                ...   \n",
       "95  the ambassadors of finland and sweden are due ...   \n",
       "96  it is senseless to create an offramp in the re...   \n",
       "97  pictures tell a thousand words videos tell ten...   \n",
       "98  putin giving up russian energy resources will ...   \n",
       "99  im proud to be listed in an article calling ou...   \n",
       "\n",
       "                                                nouns              adjectives  \\\n",
       "0                                         putin sense               senseless   \n",
       "1                                               putin               murderous   \n",
       "2       president putin task materials spread viruses      biological analyze   \n",
       "3   putins solovyov villa shores lake como italy s...                vladimir   \n",
       "4                                  i israelites putin                barbaric   \n",
       "..                                                ...                     ...   \n",
       "95  ambassadors finland sweden headquarters brusse...                due nato   \n",
       "96                          offramp world putin world  senseless real virtual   \n",
       "97                      pictures thousand words video                           \n",
       "98  putin energy resources region energy costs wor...                 highest   \n",
       "99       proud article lies guy vladimir putin person                 im same   \n",
       "\n",
       "                                         top_emotions      fear     anger  \\\n",
       "0                    [(anger, 0.25), (sadness, 0.25)]  0.000000  0.250000   \n",
       "1                                                  []  0.000000  0.000000   \n",
       "2                                                  []  0.000000  0.000000   \n",
       "3                                                  []  0.000000  0.000000   \n",
       "4   [(fear, 0.3333333333333333), (anger, 0.3333333...  0.333333  0.333333   \n",
       "..                                                ...       ...       ...   \n",
       "95                              [(anticipation, 1.0)]  0.000000  0.000000   \n",
       "96  [(fear, 0.14285714285714285), (anger, 0.142857...  0.142857  0.142857   \n",
       "97                                     [(anger, 1.0)]  0.000000  1.000000   \n",
       "98                        [(joy, 0.3333333333333333)]  0.000000  0.000000   \n",
       "99  [(anticipation, 0.3333333333333333), (trust, 0...  0.000000  0.000000   \n",
       "\n",
       "    anticipation     trust  ...  e_fear  e_anger  e_anticipation  e_trust  \\\n",
       "0       0.000000  0.000000  ...       0        0               0        0   \n",
       "1       0.000000  0.000000  ...       0        0               0        0   \n",
       "2       0.000000  0.000000  ...       0        0               0        0   \n",
       "3       0.000000  0.000000  ...       0        0               0        0   \n",
       "4       0.000000  0.000000  ...       0        0               0        0   \n",
       "..           ...       ...  ...     ...      ...             ...      ...   \n",
       "95      1.000000  0.000000  ...       0        0               0        0   \n",
       "96      0.000000  0.142857  ...       0        0               0        0   \n",
       "97      0.000000  0.000000  ...       0        0               0        0   \n",
       "98      0.000000  0.000000  ...       0        0               0        0   \n",
       "99      0.333333  0.333333  ...       0        0               0        0   \n",
       "\n",
       "    e_surprise  e_sadness  e_disgust  e_joy  sentiment_score  sentiment  \n",
       "0          0.0          0          0    0.0          -0.3818   Negative  \n",
       "1          0.0          0          0    0.0          -0.6369   Negative  \n",
       "2          0.0          0          0    0.0           0.0000    Neutral  \n",
       "3          0.0          0          0    0.0           0.0000    Neutral  \n",
       "4          0.0          0          0    0.0           0.4019   Positive  \n",
       "..         ...        ...        ...    ...              ...        ...  \n",
       "95         0.0          0          0    0.0           0.4939   Positive  \n",
       "96         0.0          0          0    0.0           0.2732   Positive  \n",
       "97         0.0          0          0    0.0           0.3400   Positive  \n",
       "98         0.0          0          0    0.0           0.6808   Positive  \n",
       "99         0.0          0          0    0.0           0.0772   Positive  \n",
       "\n",
       "[100 rows x 24 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "tweets_short = tweets[0:100]\n",
    "ed = EmotionDetector()\n",
    "res = ed.process(tweets_short)\n",
    "res.head(100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to extract emoji \n",
      "pre process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56962/56962 [04:10<00:00, 227.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 1474/56962 [00:02<03:50, 240.93it/s]"
     ]
    }
   ],
   "source": [
    "### Process dataset\n",
    "files = [\"Putin.csv\",\"Russia.csv\",\"Ukraine.csv\",\"Ukraine Russia War.csv\",\"Zelensky.csv\"]\n",
    "#files = [\"Putin.csv\"]\n",
    "ed = EmotionDetector()\n",
    "\n",
    "for file in files:\n",
    "    tweets = pd.read_csv('./data/'+file)\n",
    "    tweets = tweets.rename(columns={'0': 'text'})\n",
    "    tweets.head()\n",
    "    tweets.reset_index(drop=True)\n",
    "    res = ed.process(tweets)\n",
    "    res.to_csv('./processed_dataset/'+file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
