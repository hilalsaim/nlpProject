{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re # for regular expressions\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from textblob import TextBlob\n",
    "import advertools as adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\51588\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/plain": "                    tweetcreatedts  \\\n0       2022-04-01 00:00:00.000000   \n1       2022-04-01 00:00:00.000000   \n2       2022-04-01 00:00:00.000000   \n3       2022-04-01 00:00:00.000000   \n4       2022-04-01 00:00:00.000000   \n...                            ...   \n254621  2022-04-01 23:59:57.000000   \n254622  2022-04-01 23:59:57.000000   \n254623  2022-04-01 23:59:58.000000   \n254624  2022-04-01 23:59:58.000000   \n254625  2022-04-01 23:59:59.000000   \n\n                                                     text  \n0       ‚ö°The Ukrainian Air Force would like to address...  \n1       Chernihiv oblast. Ukrainians welcome their lib...  \n2       America üá∫üá∏ is preparing for something worse th...  \n3       JUST IN: #Anonymous has hacked &amp; released ...  \n4       ***PUBLIC MINT NOW LIVE***\\n\\nFor \\n@billionai...  \n...                                                   ...  \n254621  14-year-old Yura from #Bucha told how a Russia...  \n254622  #RussianUkrainianWar #UkraineRussianWar #Russi...  \n254623  ‚ÄúFrom where Winston stood it was just possible...  \n254624  When I said tonight in front of 3000 people In...  \n254625  We‚Äôre back. No funny stuff #UKRAINE https://t....  \n\n[254626 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweetcreatedts</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>‚ö°The Ukrainian Air Force would like to address...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>Chernihiv oblast. Ukrainians welcome their lib...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>America üá∫üá∏ is preparing for something worse th...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>JUST IN: #Anonymous has hacked &amp;amp; released ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>***PUBLIC MINT NOW LIVE***\\n\\nFor \\n@billionai...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>254621</th>\n      <td>2022-04-01 23:59:57.000000</td>\n      <td>14-year-old Yura from #Bucha told how a Russia...</td>\n    </tr>\n    <tr>\n      <th>254622</th>\n      <td>2022-04-01 23:59:57.000000</td>\n      <td>#RussianUkrainianWar #UkraineRussianWar #Russi...</td>\n    </tr>\n    <tr>\n      <th>254623</th>\n      <td>2022-04-01 23:59:58.000000</td>\n      <td>‚ÄúFrom where Winston stood it was just possible...</td>\n    </tr>\n    <tr>\n      <th>254624</th>\n      <td>2022-04-01 23:59:58.000000</td>\n      <td>When I said tonight in front of 3000 people In...</td>\n    </tr>\n    <tr>\n      <th>254625</th>\n      <td>2022-04-01 23:59:59.000000</td>\n      <td>We‚Äôre back. No funny stuff #UKRAINE https://t....</td>\n    </tr>\n  </tbody>\n</table>\n<p>254626 rows √ó 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read tweets from csv file\n",
    "tweets = pd.read_csv('./data/0401_UkraineCombinedTweetsDeduped.csv')\n",
    "tweets = tweets[tweets['language']==\"en\"]\n",
    "tweets = tweets[[\"tweetcreatedts\", \"text\"]]\n",
    "tweets.head()\n",
    "tweets.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fear': 0.5, 'anger': 0.0, 'anticipation': 0.5, 'trust': 0.0, 'surprise': 0.0, 'sadness': 0.0, 'disgust': 0.0, 'joy': 0.0}\n",
      "[('fear', 0.5), ('anticipation', 0.5)]\n",
      "[('joy', 0.3568840579710145)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from Lexicon import lexicon\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "tqdm.pandas()\n",
    "\n",
    "emoji_lexicon = pd.read_csv('resource_folder/EmoTag1200-scores.csv', sep =',')\n",
    "emoji_dict = emoji_lexicon.set_index('emoji').T.to_dict()\n",
    "emoji_factor = 0.1\n",
    "\n",
    "# extention of NRCLex, rewrite build_word_affect mehtod to add emoji analysis\n",
    "class NRCLexEx():\n",
    "    def build_word_affect(self):\n",
    "        #print('build_word_affect')\n",
    "        # Build word affect function\n",
    "        affect_list = []\n",
    "        affect_dict = dict()\n",
    "        affect_frequencies = Counter()\n",
    "        lexicon_keys = lexicon.keys()\n",
    "        for word in self.words:\n",
    "            if word in lexicon_keys:\n",
    "                affect_list.extend(lexicon[word])\n",
    "                affect_dict.update({word: lexicon[word]})\n",
    "        for word in affect_list:\n",
    "            affect_frequencies[word] += 1\n",
    "        sum_values = sum(affect_frequencies.values())\n",
    "        affect_percent = {'fear': 0.0, 'anger': 0.0, 'anticipation': 0.0, 'trust': 0.0, 'surprise': 0.0, 'sadness': 0.0, 'disgust': 0.0, 'joy': 0.0}\n",
    "        emoji_affect_percent = {'fear': 0.0, 'anger': 0.0, 'anticipation': 0.0, 'trust': 0.0, 'surprise': 0.0, 'sadness': 0.0, 'disgust': 0.0, 'joy': 0.0}\n",
    "        for key in affect_frequencies.keys():\n",
    "            affect_percent.update({key: float(affect_frequencies[key]) / float(sum_values)})\n",
    "\n",
    "        emoji_affect_frequencies = Counter()\n",
    "        if len(affect_list) > 0:\n",
    "            for emoji in self.emojis:\n",
    "                #print(emoji)\n",
    "                if emoji in emoji_dict.keys():\n",
    "                    emoji_affect_dic = emoji_dict[emoji]\n",
    "                    #print(emoji_affect_frequencies)\n",
    "                    for key in affect_percent.keys():\n",
    "                        if emoji_affect_dic[key] > 0:\n",
    "                            emoji_affect_frequencies[key] += emoji_affect_dic[key]\n",
    "        emoji_sum_values = sum(emoji_affect_frequencies.values())\n",
    "        #print('emoji_sum_values',emoji_sum_values)\n",
    "        #print('emoji_affect_frequencies',emoji_affect_frequencies)\n",
    "        for key in emoji_affect_frequencies.keys():\n",
    "            #print(float(emoji_affect_frequencies[key]),float(emoji_sum_values),float(emoji_affect_frequencies[key]) / float(emoji_sum_values))\n",
    "            #freq = float(emoji_affect_frequencies[key]) / float(emoji_sum_values)\n",
    "            #print(freq)\n",
    "            emoji_affect_percent.update({key: float(emoji_affect_frequencies[key]) / float(emoji_sum_values)})\n",
    "            #print(key,'emoji_affect_frequencies',emoji_affect_frequencies)\n",
    "        self.affect_list = affect_list\n",
    "        self.raw_emotion_scores = dict(affect_frequencies)\n",
    "        self.affect_frequencies = affect_percent\n",
    "        self.emoji_affect_frequencies = emoji_affect_percent\n",
    "\n",
    "    def __init__(self,text,emojis):\n",
    "        self.text = text\n",
    "        blob = TextBlob(text)\n",
    "        self.words = list(blob.words)\n",
    "        self.sentences = list(blob.sentences)\n",
    "        self.emojis = emojis\n",
    "        self.build_word_affect()\n",
    "        self.top_emotions()\n",
    "\n",
    "    # get top emotins based on accumulate score\n",
    "    def top_emotions(self):\n",
    "        emo_dict = self.affect_frequencies\n",
    "        max_value = max(emo_dict.values())\n",
    "        top_emotions = []\n",
    "        for key in emo_dict.keys():\n",
    "            if emo_dict[key] == max_value and max_value > 0:\n",
    "                top_emotions.append((key, max_value))\n",
    "        self.top_emotions = top_emotions\n",
    "        emoji_emo_dict = self.emoji_affect_frequencies\n",
    "        emoji_max_value = max(emoji_emo_dict.values())\n",
    "        top_emoji_emotions = []\n",
    "        for key in emoji_emo_dict.keys():\n",
    "            if emoji_emo_dict[key] == emoji_max_value and emoji_max_value > 0:\n",
    "                top_emoji_emotions.append((key, emoji_max_value))\n",
    "        self.top_emoji_emotions = top_emoji_emotions\n",
    "\n",
    "# Test\n",
    "#text_object = NRCLexEx(\"o denote the measurements of some unknown quantity V,\"\n",
    "                        \" and sought the  estimator of that quantity\",['üåà', 'üëè', 'üëè','üôÑ'])\n",
    "#print(text_object.affect_frequencies);\n",
    "#print(text_object.top_emotions);\n",
    "#print(text_object.top_emoji_emotions);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EmotionDetector:\n",
    "    # copyed from nrclex.py, remove positive and negative emotions\n",
    "\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    tk = TweetTokenizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "    # initialize lexicon\n",
    "    def __init__(self, emoji_factor = 1):\n",
    "        # load lexico from https://github.com/abushoeb/EmoTag for emoji emotion detection\n",
    "        self.emoji_factor = emoji_factor\n",
    "\n",
    "    def process(self, dataFrame, columnName='text'):\n",
    "        print(\"begin to extract emoji \")\n",
    "        emoji_summary = adv.extract_emoji(dataFrame[columnName])\n",
    "        dataFrame['emojis'] = emoji_summary['emoji']\n",
    "        print(\"pre process\")\n",
    "        pre_process_res= dataFrame[columnName].progress_apply(EmotionDetector.pre_process)\n",
    "        dataFrame = pd.concat([dataFrame, pre_process_res], axis=1)\n",
    "        print(\"emotion analysis\")\n",
    "        res = dataFrame.progress_apply(self.emotion_analysis,axis=1)\n",
    "        res.head()\n",
    "        dataFrame = pd.concat([dataFrame, res], axis=1)\n",
    "        print(\"sentiment analysis\")\n",
    "        sentiment_analysis_res = dataFrame.progress_apply(self.sentiment_analysis,axis=1)\n",
    "        dataFrame = pd.concat([dataFrame, sentiment_analysis_res], axis=1)\n",
    "        return dataFrame\n",
    "\n",
    "    # sentiment analysis method\n",
    "    def sentiment_analysis(self, row):\n",
    "        words = row[\"tokens\"]\n",
    "        score = EmotionDetector.analyser.polarity_scores(str(words))\n",
    "        score=score['compound']\n",
    "        res = 'Neutral'\n",
    "        if score>=0.05:\n",
    "            res = 'Positive'\n",
    "        elif score<=-0.05:\n",
    "            res = 'Negative'\n",
    "        else:\n",
    "            res = 'Neutral'\n",
    "        return pd.Series([score,res],\n",
    "                         index=['sentiment_score', 'sentiment'])\n",
    "\n",
    "    # emotion analysis method\n",
    "    def emotion_analysis(self, row):\n",
    "        #print(\"1111\")\n",
    "        #print(row)\n",
    "        text = row[\"text\"]\n",
    "        emojis = row['emojis']\n",
    "        emotions = NRCLexEx(text,emojis)\n",
    "        top_emotions = emotions.top_emotions\n",
    "        top_emoji_emotions = emotions.top_emoji_emotions\n",
    "        top_emotions_dict = {'fear': 0, 'anger': 0, 'anticipation': 0, 'trust': 0, 'surprise': 0,\n",
    "                             'sadness': 0, 'disgust': 0, 'joy': 0}\n",
    "        top_eomji_emotions_dict = {'e_fear': 0, 'e_anger': 0, 'e_anticipation': 0, 'e_trust': 0, 'e_surprise': 0,\n",
    "                             'e_sadness': 0, 'e_disgust': 0, 'e_joy': 0}\n",
    "        #print(top_emotions)\n",
    "        for key,value in top_emotions:\n",
    "            top_emotions_dict[key] = value\n",
    "        for key,value in top_emoji_emotions:\n",
    "            top_eomji_emotions_dict['e_'+key] = value\n",
    "        # print(top_emotions_dict.values())\n",
    "        # print(top_emotions_dict.keys())\n",
    "        # res = [affect_list,affect_dict,dict(affect_frequencies),affect_percent,top_emotions]\n",
    "        # res = res.append()\n",
    "        return pd.Series([top_emotions,*top_emotions_dict.values(),*top_eomji_emotions_dict.values()],\n",
    "                         index=['top_emotions',*top_emotions_dict.keys(),*top_eomji_emotions_dict.keys()])\n",
    "\n",
    "    @staticmethod\n",
    "    def pre_process(text):\n",
    "        #print(text)\n",
    "        # clean text\n",
    "        text = EmotionDetector.cleanText(str(text))\n",
    "        #print(text)\n",
    "        #emoji_summary = adv.extract_emoji([text])\n",
    "        #print(emoji_summary['emoji'])\n",
    "        #tokenization = nltk.word_tokenize(text)\n",
    "        # tokenization = EmotionDetector.tk.tokenize(text)\n",
    "\n",
    "        blob = TextBlob(text)\n",
    "        filtered_words = [word.lower() for word in blob.words]\n",
    "        nouns = []\n",
    "        adjectives = []\n",
    "        for word, tag in pos_tag(filtered_words):\n",
    "            # since most tweets contain such words, it is not helpful for future analysis\n",
    "            if word.startswith(\"russi\") or word.startswith(\"ukrai\"):\n",
    "                continue\n",
    "            if tag.startswith(\"NN\"): #Nouns\n",
    "                nouns.append(word)\n",
    "            elif tag.startswith(\"JJ\"): #Adjective\n",
    "                adjectives.append(word)\n",
    "\n",
    "        # map_object = map(EmotionDetector.stemmer.stem, filtered_words)\n",
    "        # lemma_words = list(map_object)\n",
    "        #print(lemma_words)\n",
    "        return pd.Series([' '.join(filtered_words),' '.join(nouns),' '.join(adjectives)],\n",
    "                         index=['tokens', 'nouns', 'adjectives'])\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def cleanText(text):\n",
    "        text=text.lower()\n",
    "        text = re.sub(r'(?i)RT @\\w+: ','', text) # remove RT\n",
    "        text = re.sub(r'@\\w+','', text) # remove @member\n",
    "        text = re.sub(r'#','', text) # remove # symbol\n",
    "        text = re.sub(r'https?:\\/\\/\\S+','', text) # remove the hyper link\n",
    "        text = re.sub(r'[^\\w\\s]', '', text) # remove punctuations\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-c7c433db7cfe>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataFrame['emojis'] = emoji_summary['emoji']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to extract emoji \n",
      "pre process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 386.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 917.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 1785.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 tweetcreatedts  \\\n0    2022-04-01 00:00:00.000000   \n1    2022-04-01 00:00:00.000000   \n2    2022-04-01 00:00:00.000000   \n3    2022-04-01 00:00:00.000000   \n4    2022-04-01 00:00:00.000000   \n..                          ...   \n123  2022-04-01 00:00:30.000000   \n124  2022-04-01 00:00:30.000000   \n125  2022-04-01 00:00:31.000000   \n127  2022-04-01 00:00:31.000000   \n128  2022-04-01 00:00:31.000000   \n\n                                                  text  \\\n0    ‚ö°The Ukrainian Air Force would like to address...   \n1    Chernihiv oblast. Ukrainians welcome their lib...   \n2    America üá∫üá∏ is preparing for something worse th...   \n3    JUST IN: #Anonymous has hacked &amp; released ...   \n4    ***PUBLIC MINT NOW LIVE***\\n\\nFor \\n@billionai...   \n..                                                 ...   \n123  üíôüíõ  Cover of the April issue of Polish Vogue \\...   \n124  #Ukrainian forces successfully conducted local...   \n125  ‚ö°The Ukrainian Air Force would like to address...   \n127  ‚ùåMyth: The US and @NATO are providing #Ukraine...   \n128  Scramble for #gas #settodraw US$10B into #Tanz...   \n\n                      emojis  \\\n0                 [‚ö°, üá∫üá¶, üßµ]   \n1                         []   \n2    [üá∫üá∏, üáπüáº, üá∑üá∫, üá∫üá∏, üá®üá≥, üëá]   \n3                         []   \n4                         []   \n..                       ...   \n123                   [üíô, üíõ]   \n124                       []   \n125               [‚ö°, üá∫üá¶, üßµ]   \n127                   [‚ùå, ‚úÖ]   \n128                       []   \n\n                                                tokens  \\\n0    the ukrainian air force would like to address ...   \n1    chernihiv oblast ukrainians welcome their libe...   \n2    america is preparing for something worse than ...   \n3    just in anonymous has hacked amp released 6200...   \n4    public mint now live for win 100000 during pub...   \n..                                                 ...   \n123  cover of the april issue of polish vogue it wa...   \n124  ukrainian forces successfully conducted local ...   \n125  the ukrainian air force would like to address ...   \n127  myth the us and are providing ukraine with nee...   \n128  scramble for gas settodraw us10b into tanzania...   \n\n                                                 nouns  \\\n0    air force misinformation media outlets situati...   \n1    chernihiv oblast liberators standwithukraine s...   \n2    america something month war policy future rela...   \n3    amp emails marathon group investment firm olig...   \n4       mint sale mint visit information luck nft mint   \n..                                                 ...   \n123  cover issue vogue fashion photographer artist ...   \n124  forces counterattacks kyiv towards sumy kherso...   \n125  air force misinformation media outlets situati...   \n127  weapons allies everything involvement war trut...   \n128  gas settodraw us10b tanzaniaproject africa ene...   \n\n                               adjectives  \\\n0           multiple western protectu–∞sky   \n1                     putinisawarcriminal   \n2    worse last new cold best taiwan full   \n3                    anonymous eu foreign   \n4              public public further good   \n..                                    ...   \n123                          april polish   \n124   local further northwest coming full   \n125         multiple western protectu–∞sky   \n127          needed possible short direct   \n128                              scramble   \n\n                                          top_emotions  fear  anger  \\\n0                                                   []  0.00   0.00   \n1                                                   []  0.00   0.00   \n2                                        [(fear, 0.5)]  0.50   0.00   \n3                                                   []  0.00   0.00   \n4                                [(anticipation, 1.0)]  0.00   0.00   \n..                                                 ...   ...    ...   \n123                                                 []  0.00   0.00   \n124                              [(anticipation, 1.0)]  0.00   0.00   \n125                                                 []  0.00   0.00   \n127  [(fear, 0.25), (anger, 0.25), (anticipation, 0...  0.25   0.25   \n128                                                 []  0.00   0.00   \n\n     anticipation  ...  e_fear  e_anger  e_anticipation  e_trust  e_surprise  \\\n0            0.00  ...       0        0        0.000000        0           0   \n1            0.00  ...       0        0        0.000000        0           0   \n2            0.00  ...       0        0        0.333333        0           0   \n3            0.00  ...       0        0        0.000000        0           0   \n4            1.00  ...       0        0        0.000000        0           0   \n..            ...  ...     ...      ...             ...      ...         ...   \n123          0.00  ...       0        0        0.000000        0           0   \n124          1.00  ...       0        0        0.000000        0           0   \n125          0.00  ...       0        0        0.000000        0           0   \n127          0.25  ...       0        0        0.000000        0           0   \n128          0.00  ...       0        0        0.000000        0           0   \n\n     e_sadness  e_disgust  e_joy  sentiment_score  sentiment  \n0            0   0.000000    0.0           0.4404   Positive  \n1            0   0.000000    0.0           0.4588   Positive  \n2            0   0.000000    0.0          -0.4215   Negative  \n3            0   0.000000    0.0          -0.4019   Negative  \n4            0   0.000000    0.0           0.8658   Positive  \n..         ...        ...    ...              ...        ...  \n123          0   0.000000    0.0           0.2500    Neutral  \n124          0   0.000000    0.0           0.4939   Positive  \n125          0   0.000000    0.0           0.4404   Positive  \n127          0   0.210909    0.0          -0.1779    Neutral  \n128          0   0.000000    0.0           0.2732    Neutral  \n\n[100 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweetcreatedts</th>\n      <th>text</th>\n      <th>emojis</th>\n      <th>tokens</th>\n      <th>nouns</th>\n      <th>adjectives</th>\n      <th>top_emotions</th>\n      <th>fear</th>\n      <th>anger</th>\n      <th>anticipation</th>\n      <th>...</th>\n      <th>e_fear</th>\n      <th>e_anger</th>\n      <th>e_anticipation</th>\n      <th>e_trust</th>\n      <th>e_surprise</th>\n      <th>e_sadness</th>\n      <th>e_disgust</th>\n      <th>e_joy</th>\n      <th>sentiment_score</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>‚ö°The Ukrainian Air Force would like to address...</td>\n      <td>[‚ö°, üá∫üá¶, üßµ]</td>\n      <td>the ukrainian air force would like to address ...</td>\n      <td>air force misinformation media outlets situati...</td>\n      <td>multiple western protectu–∞sky</td>\n      <td>[]</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.4404</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>Chernihiv oblast. Ukrainians welcome their lib...</td>\n      <td>[]</td>\n      <td>chernihiv oblast ukrainians welcome their libe...</td>\n      <td>chernihiv oblast liberators standwithukraine s...</td>\n      <td>putinisawarcriminal</td>\n      <td>[]</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.4588</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>America üá∫üá∏ is preparing for something worse th...</td>\n      <td>[üá∫üá∏, üáπüáº, üá∑üá∫, üá∫üá∏, üá®üá≥, üëá]</td>\n      <td>america is preparing for something worse than ...</td>\n      <td>america something month war policy future rela...</td>\n      <td>worse last new cold best taiwan full</td>\n      <td>[(fear, 0.5)]</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.333333</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>-0.4215</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>JUST IN: #Anonymous has hacked &amp;amp; released ...</td>\n      <td>[]</td>\n      <td>just in anonymous has hacked amp released 6200...</td>\n      <td>amp emails marathon group investment firm olig...</td>\n      <td>anonymous eu foreign</td>\n      <td>[]</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>-0.4019</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>***PUBLIC MINT NOW LIVE***\\n\\nFor \\n@billionai...</td>\n      <td>[]</td>\n      <td>public mint now live for win 100000 during pub...</td>\n      <td>mint sale mint visit information luck nft mint</td>\n      <td>public public further good</td>\n      <td>[(anticipation, 1.0)]</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.8658</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>2022-04-01 00:00:30.000000</td>\n      <td>üíôüíõ  Cover of the April issue of Polish Vogue \\...</td>\n      <td>[üíô, üíõ]</td>\n      <td>cover of the april issue of polish vogue it wa...</td>\n      <td>cover issue vogue fashion photographer artist ...</td>\n      <td>april polish</td>\n      <td>[]</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.2500</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>2022-04-01 00:00:30.000000</td>\n      <td>#Ukrainian forces successfully conducted local...</td>\n      <td>[]</td>\n      <td>ukrainian forces successfully conducted local ...</td>\n      <td>forces counterattacks kyiv towards sumy kherso...</td>\n      <td>local further northwest coming full</td>\n      <td>[(anticipation, 1.0)]</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.4939</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>2022-04-01 00:00:31.000000</td>\n      <td>‚ö°The Ukrainian Air Force would like to address...</td>\n      <td>[‚ö°, üá∫üá¶, üßµ]</td>\n      <td>the ukrainian air force would like to address ...</td>\n      <td>air force misinformation media outlets situati...</td>\n      <td>multiple western protectu–∞sky</td>\n      <td>[]</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.4404</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>2022-04-01 00:00:31.000000</td>\n      <td>‚ùåMyth: The US and @NATO are providing #Ukraine...</td>\n      <td>[‚ùå, ‚úÖ]</td>\n      <td>myth the us and are providing ukraine with nee...</td>\n      <td>weapons allies everything involvement war trut...</td>\n      <td>needed possible short direct</td>\n      <td>[(fear, 0.25), (anger, 0.25), (anticipation, 0...</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.210909</td>\n      <td>0.0</td>\n      <td>-0.1779</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>128</th>\n      <td>2022-04-01 00:00:31.000000</td>\n      <td>Scramble for #gas #settodraw US$10B into #Tanz...</td>\n      <td>[]</td>\n      <td>scramble for gas settodraw us10b into tanzania...</td>\n      <td>gas settodraw us10b tanzaniaproject africa ene...</td>\n      <td>scramble</td>\n      <td>[]</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.2732</td>\n      <td>Neutral</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows √ó 25 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "tweets_short = tweets[0:100]\n",
    "ed = EmotionDetector()\n",
    "res = ed.process(tweets_short)\n",
    "res.head(100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to extract emoji \n",
      "pre process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 56962/56962 [03:20<00:00, 284.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 56962/56962 [01:02<00:00, 916.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 56962/56962 [00:32<00:00, 1770.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to extract emoji \n",
      "pre process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50966/50966 [01:55<00:00, 442.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50966/50966 [00:49<00:00, 1034.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50966/50966 [00:26<00:00, 1951.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to extract emoji \n",
      "pre process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 61459/61459 [02:20<00:00, 436.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 61459/61459 [01:04<00:00, 946.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 61459/61459 [00:36<00:00, 1677.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to extract emoji \n",
      "pre process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 56962/56962 [02:12<00:00, 431.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 56962/56962 [01:07<00:00, 849.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 56962/56962 [00:34<00:00, 1640.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to extract emoji \n",
      "pre process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 59960/59960 [02:09<00:00, 464.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 59960/59960 [00:55<00:00, 1086.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 59960/59960 [00:28<00:00, 2127.43it/s]\n"
     ]
    }
   ],
   "source": [
    "### Process dataset\n",
    "files = [\"Putin.csv\",\"Russia.csv\",\"Ukraine.csv\",\"Ukraine Russia War.csv\",\"Zelensky.csv\"]\n",
    "#files = [\"Putin.csv\"]\n",
    "ed = EmotionDetector()\n",
    "\n",
    "for file in files:\n",
    "    tweets = pd.read_csv('./data/'+file)\n",
    "    tweets = tweets.rename(columns={'0': 'text'})\n",
    "    tweets.head()\n",
    "    tweets.reset_index(drop=True)\n",
    "    res = ed.process(tweets)\n",
    "    res.to_csv('./processed_dataset/'+file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}