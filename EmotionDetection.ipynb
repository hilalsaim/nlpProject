{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "from datetime import date\n",
    "\n",
    "import re # for regular expressions\n",
    "import string\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from textblob import TextBlob\n",
    "import advertools as adv\n",
    "from nrclex import NRCLex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\51588\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/plain": "                    tweetcreatedts  \\\n0       2022-04-01 00:00:00.000000   \n1       2022-04-01 00:00:00.000000   \n2       2022-04-01 00:00:00.000000   \n3       2022-04-01 00:00:00.000000   \n4       2022-04-01 00:00:00.000000   \n...                            ...   \n254621  2022-04-01 23:59:57.000000   \n254622  2022-04-01 23:59:57.000000   \n254623  2022-04-01 23:59:58.000000   \n254624  2022-04-01 23:59:58.000000   \n254625  2022-04-01 23:59:59.000000   \n\n                                                     text  \n0       âš¡The Ukrainian Air Force would like to address...  \n1       Chernihiv oblast. Ukrainians welcome their lib...  \n2       America ðŸ‡ºðŸ‡¸ is preparing for something worse th...  \n3       JUST IN: #Anonymous has hacked &amp; released ...  \n4       ***PUBLIC MINT NOW LIVE***\\n\\nFor \\n@billionai...  \n...                                                   ...  \n254621  14-year-old Yura from #Bucha told how a Russia...  \n254622  #RussianUkrainianWar #UkraineRussianWar #Russi...  \n254623  â€œFrom where Winston stood it was just possible...  \n254624  When I said tonight in front of 3000 people In...  \n254625  Weâ€™re back. No funny stuff #UKRAINE https://t....  \n\n[254626 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweetcreatedts</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>âš¡The Ukrainian Air Force would like to address...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>Chernihiv oblast. Ukrainians welcome their lib...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>America ðŸ‡ºðŸ‡¸ is preparing for something worse th...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>JUST IN: #Anonymous has hacked &amp;amp; released ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>***PUBLIC MINT NOW LIVE***\\n\\nFor \\n@billionai...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>254621</th>\n      <td>2022-04-01 23:59:57.000000</td>\n      <td>14-year-old Yura from #Bucha told how a Russia...</td>\n    </tr>\n    <tr>\n      <th>254622</th>\n      <td>2022-04-01 23:59:57.000000</td>\n      <td>#RussianUkrainianWar #UkraineRussianWar #Russi...</td>\n    </tr>\n    <tr>\n      <th>254623</th>\n      <td>2022-04-01 23:59:58.000000</td>\n      <td>â€œFrom where Winston stood it was just possible...</td>\n    </tr>\n    <tr>\n      <th>254624</th>\n      <td>2022-04-01 23:59:58.000000</td>\n      <td>When I said tonight in front of 3000 people In...</td>\n    </tr>\n    <tr>\n      <th>254625</th>\n      <td>2022-04-01 23:59:59.000000</td>\n      <td>Weâ€™re back. No funny stuff #UKRAINE https://t....</td>\n    </tr>\n  </tbody>\n</table>\n<p>254626 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read tweets from csv file\n",
    "tweets = pd.read_csv('./data/0401_UkraineCombinedTweetsDeduped.csv')\n",
    "tweets = tweets[tweets['language']==\"en\"]\n",
    "tweets = tweets[[\"tweetcreatedts\", \"text\"]]\n",
    "tweets.head()\n",
    "tweets.reset_index(drop=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "# for test propose, reduce records\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fear': 0.5, 'anger': 0.008, 'anticipation': 0.5529999999999999, 'trust': 0.0695, 'surprise': 0.036000000000000004, 'sadness': 0.003, 'disgust': 0.008, 'joy': 0.0985}\n",
      "[('anticipation', 0.5529999999999999)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from nrclex import NRCLex\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from Lexicon import lexicon\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "emoji_lexicon = pd.read_csv('resource_folder/EmoTag1200-scores.csv', sep =',')\n",
    "emoji_dict = emoji_lexicon.set_index('emoji').T.to_dict()\n",
    "emoji_factor = 0.1\n",
    "\n",
    "class NRCLexEx():\n",
    "    def build_word_affect(self):\n",
    "        #print('build_word_affect')\n",
    "        # Build word affect function\n",
    "        affect_list = []\n",
    "        affect_dict = dict()\n",
    "        affect_frequencies = Counter()\n",
    "        lexicon_keys = lexicon.keys()\n",
    "        for word in self.words:\n",
    "            if word in lexicon_keys:\n",
    "                affect_list.extend(lexicon[word])\n",
    "                affect_dict.update({word: lexicon[word]})\n",
    "        for word in affect_list:\n",
    "            affect_frequencies[word] += 1\n",
    "        sum_values = sum(affect_frequencies.values())\n",
    "        affect_percent = {'fear': 0.0, 'anger': 0.0, 'anticipation': 0.0, 'trust': 0.0, 'surprise': 0.0, 'sadness': 0.0, 'disgust': 0.0, 'joy': 0.0}\n",
    "\n",
    "        if len(affect_list) > 0:\n",
    "            for emoji in self.emojis:\n",
    "                #print(emoji)\n",
    "                if emoji in emoji_dict.keys():\n",
    "                    emoji_affect_dic = emoji_dict[emoji]\n",
    "                    #print(emoji_affect_dic)\n",
    "                    for key in affect_percent.keys():\n",
    "                        if emoji_affect_dic[key] > 0:\n",
    "                            affect_frequencies[key] += emoji_affect_dic[key] * emoji_factor\n",
    "                            affect_list.append(key)\n",
    "        for key in affect_frequencies.keys():\n",
    "            affect_percent.update({key: float(affect_frequencies[key]) / float(sum_values)})\n",
    "        self.affect_list = affect_list\n",
    "        self.raw_emotion_scores = dict(affect_frequencies)\n",
    "        self.affect_frequencies = affect_percent\n",
    "    def __init__(self,text,emojis):\n",
    "        self.text = text\n",
    "        blob = TextBlob(text)\n",
    "        self.words = list(blob.words)\n",
    "        self.sentences = list(blob.sentences)\n",
    "        self.emojis = emojis\n",
    "        self.build_word_affect()\n",
    "        self.top_emotions()\n",
    "    def top_emotions(self):\n",
    "        emo_dict = self.affect_frequencies\n",
    "        max_value = max(emo_dict.values())\n",
    "        top_emotions = []\n",
    "        for key in emo_dict.keys():\n",
    "            if emo_dict[key] == max_value and max_value > 0:\n",
    "                top_emotions.append((key, max_value))\n",
    "        self.top_emotions = top_emotions\n",
    "\n",
    "text_object = NRCLexEx(\"o denote the measurements of some unknown quantity V,\"\n",
    "                       \" and sought the  estimator of that quantity\",['ðŸŒˆ', 'ðŸ‘', 'ðŸ‘','ðŸ™„'])\n",
    "print(text_object.affect_frequencies)\n",
    "print(text_object.top_emotions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "class EmotionDetector:\n",
    "    # copyed from nrclex.py, remove positive and negative emotions\n",
    "\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    tk = TweetTokenizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    # initialize lexicon\n",
    "    def __init__(self, emoji_factor = 1):\n",
    "        # load lexico from https://github.com/abushoeb/EmoTag for emoji emotion detection\n",
    "        self.emoji_factor = emoji_factor\n",
    "\n",
    "    def process(self, dataFrame, columnName='text'):\n",
    "        print(\"begin to extract emoji \")\n",
    "        emoji_summary = adv.extract_emoji(dataFrame[columnName])\n",
    "        dataFrame['emojis'] = emoji_summary['emoji']\n",
    "        print(\"pre process\")\n",
    "        pre_process_res= dataFrame[columnName].progress_apply(EmotionDetector.pre_process)\n",
    "        dataFrame = pd.concat([dataFrame, pre_process_res], axis=1)\n",
    "        print(\"emotion analysis\")\n",
    "        res = dataFrame.progress_apply(self.emotion_analysis,axis=1)\n",
    "        res.head()\n",
    "        dataFrame = pd.concat([dataFrame, res], axis=1)\n",
    "        print(\"sentiment analysis\")\n",
    "        sentiment_analysis_res = dataFrame.progress_apply(self.sentiment_analysis,axis=1)\n",
    "        dataFrame = pd.concat([dataFrame, sentiment_analysis_res], axis=1)\n",
    "        return dataFrame\n",
    "\n",
    "\n",
    "    def sentiment_analysis(self, row):\n",
    "        words = row[\"tokens\"]\n",
    "        score = EmotionDetector.analyser.polarity_scores(str(words))\n",
    "        score=score['compound']\n",
    "        res = 'Neutral'\n",
    "        if score>=0.5:\n",
    "            res = 'Positive'\n",
    "        elif score<=-0.05:\n",
    "            res = 'Negative'\n",
    "        else:\n",
    "            res = 'Neutral'\n",
    "        return pd.Series([score,res],\n",
    "                         index=['sentiment_score', 'sentiment'])\n",
    "\n",
    "    def emotion_analysis(self, row):\n",
    "        #print(\"1111\")\n",
    "        #print(row)\n",
    "        text = row[\"text\"]\n",
    "        emojis = row['emojis']\n",
    "        emotions = NRCLexEx(text,emojis)\n",
    "        top_emotions = emotions.top_emotions\n",
    "        top_emotions_dict = {'fear': 0, 'anger': 0, 'anticipation': 0, 'trust': 0, 'surprise': 0,\n",
    "                             'sadness': 0, 'disgust': 0, 'joy': 0}\n",
    "        #print(top_emotions)\n",
    "        for key,value in top_emotions:\n",
    "            top_emotions_dict[key] = 1\n",
    "        # print(top_emotions_dict.values())\n",
    "        # print(top_emotions_dict.keys())\n",
    "        # res = [affect_list,affect_dict,dict(affect_frequencies),affect_percent,top_emotions]\n",
    "        # res = res.append()\n",
    "        return pd.Series([top_emotions,*top_emotions_dict.values()],\n",
    "                         index=['top_emotions',*top_emotions_dict.keys()])\n",
    "\n",
    "    @staticmethod\n",
    "    def pre_process(text):\n",
    "        #print(text)\n",
    "        # clean text\n",
    "        text = EmotionDetector.cleanText(str(text))\n",
    "        #print(text)\n",
    "        #emoji_summary = adv.extract_emoji([text])\n",
    "        #print(emoji_summary['emoji'])\n",
    "        #tokenization = nltk.word_tokenize(text)\n",
    "        # tokenization = EmotionDetector.tk.tokenize(text)\n",
    "\n",
    "        blob = TextBlob(text)\n",
    "        filtered_words = [word.lower() for word in blob.words]\n",
    "        nouns = []\n",
    "        adjectives = []\n",
    "        for word, tag in pos_tag(filtered_words):\n",
    "            # since most tweets contain such words, it is not helpful for future analysis\n",
    "            if word.startswith(\"russi\") or word.startswith(\"ukrai\"):\n",
    "                continue\n",
    "            if tag.startswith(\"NN\"): #Nouns\n",
    "                nouns.append(word)\n",
    "            elif tag.startswith(\"JJ\"): #Adjective\n",
    "                adjectives.append(word)\n",
    "\n",
    "        # map_object = map(EmotionDetector.stemmer.stem, filtered_words)\n",
    "        # lemma_words = list(map_object)\n",
    "        #print(lemma_words)\n",
    "        return pd.Series([' '.join(filtered_words),' '.join(nouns),' '.join(adjectives)],\n",
    "                         index=['tokens', 'nouns', 'adjectives'])\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def cleanText(text):\n",
    "        text=text.lower()\n",
    "        text = re.sub(r'(?i)RT @\\w+: ','', text) # remove RT\n",
    "        text = re.sub(r'@\\w+','', text) # remove @member\n",
    "        text = re.sub(r'#','', text) # remove # symbol\n",
    "        text = re.sub(r'https?:\\/\\/\\S+','', text) # remove the hyper link\n",
    "        text = re.sub(r'[^\\w\\s]', '', text) # remove punctuations\n",
    "        return text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-d802707c893b>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataFrame['emojis'] = emoji_summary['emoji']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to extract emoji \n",
      "pre process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 322.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 664.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 1655.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "               tweetcreatedts  \\\n0  2022-04-01 00:00:00.000000   \n1  2022-04-01 00:00:00.000000   \n2  2022-04-01 00:00:00.000000   \n3  2022-04-01 00:00:00.000000   \n4  2022-04-01 00:00:00.000000   \n5  2022-04-01 00:00:00.000000   \n6  2022-04-01 00:00:00.000000   \n7  2022-04-01 00:00:00.000000   \n8  2022-04-01 00:00:00.000000   \n9  2022-04-01 00:00:00.000000   \n\n                                                text                   emojis  \\\n0  âš¡The Ukrainian Air Force would like to address...               [âš¡, ðŸ‡ºðŸ‡¦, ðŸ§µ]   \n1  Chernihiv oblast. Ukrainians welcome their lib...                       []   \n2  America ðŸ‡ºðŸ‡¸ is preparing for something worse th...  [ðŸ‡ºðŸ‡¸, ðŸ‡¹ðŸ‡¼, ðŸ‡·ðŸ‡º, ðŸ‡ºðŸ‡¸, ðŸ‡¨ðŸ‡³, ðŸ‘‡]   \n3  JUST IN: #Anonymous has hacked &amp; released ...                       []   \n4  ***PUBLIC MINT NOW LIVE***\\n\\nFor \\n@billionai...                       []   \n5  The Amazing story of Former Sussex County Dela...                     [ðŸ‡ºðŸ‡¸]   \n6  &amp;quot;How we were waiting for you!&amp;quo...                       []   \n7  India's purchase of discounted #Russian crude ...                       []   \n8  The most basic tenet of what stability exists ...                       []   \n9  \"The image that Russia acquired over the past ...                       []   \n\n                                              tokens  \\\n0  the ukrainian air force would like to address ...   \n1  chernihiv oblast ukrainians welcome their libe...   \n2  america is preparing for something worse than ...   \n3  just in anonymous has hacked amp released 6200...   \n4  public mint now live for win 100000 during pub...   \n5  the amazing story of former sussex county dela...   \n6  ampquothow we were waiting for youampquot in t...   \n7  indias purchase of discounted russian crude oi...   \n8  the most basic tenet of what stability exists ...   \n9  the image that russia acquired over the past t...   \n\n                                               nouns  \\\n0  air force misinformation media outlets situati...   \n1  chernihiv oblast liberators standwithukraine s...   \n2  america something month war policy future rela...   \n3  amp emails marathon group investment firm olig...   \n4     mint sale mint visit information luck nft mint   \n5  story sussex county delaware vance phillips en...   \n6  ampquothow youampquot region residents defende...   \n7  purchase crude oil place payment system trade ...   \n8  tenet stability world borders threat use force...   \n9  image decades putinmedvedev rule power abdÃ¼lme...   \n\n                                          adjectives  \\\n0                      multiple western protectuÐ°sky   \n1                                putinisawarcriminal   \n2               worse last new cold best taiwan full   \n3                               anonymous eu foreign   \n4                         public public further good   \n5  amazing former councilman difficult successful...   \n6             chernihiv local novaya chernihiv armed   \n7                indias rupeeruble bilateral western   \n8                                basic international   \n9                                        past global   \n\n                                        top_emotions  fear  anger  \\\n0                                                 []     0      0   \n1                                                 []     0      0   \n2                                   [(fear, 0.5015)]     1      0   \n3                                                 []     0      0   \n4                              [(anticipation, 1.0)]     0      0   \n5                                      [(fear, 0.4)]     1      0   \n6  [(anticipation, 0.25), (trust, 0.25), (surpris...     0      0   \n7                      [(trust, 0.6666666666666666)]     0      0   \n8                        [(fear, 0.5), (anger, 0.5)]     1      1   \n9  [(fear, 0.2), (anger, 0.2), (anticipation, 0.2...     1      1   \n\n   anticipation  trust  surprise  sadness  disgust  joy  sentiment_score  \\\n0             0      0         0        0        0    0           0.4404   \n1             0      0         0        0        0    0           0.4588   \n2             0      0         0        0        0    0          -0.4215   \n3             0      0         0        0        0    0          -0.4019   \n4             1      0         0        0        0    0           0.8658   \n5             0      0         0        0        0    0           0.9100   \n6             1      1         1        0        0    1           0.4939   \n7             0      1         0        0        0    0          -0.5423   \n8             0      0         0        0        0    0          -0.5267   \n9             1      1         0        0        0    1          -0.5574   \n\n  sentiment  \n0   Neutral  \n1   Neutral  \n2  Negative  \n3  Negative  \n4  Positive  \n5  Positive  \n6   Neutral  \n7  Negative  \n8  Negative  \n9  Negative  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweetcreatedts</th>\n      <th>text</th>\n      <th>emojis</th>\n      <th>tokens</th>\n      <th>nouns</th>\n      <th>adjectives</th>\n      <th>top_emotions</th>\n      <th>fear</th>\n      <th>anger</th>\n      <th>anticipation</th>\n      <th>trust</th>\n      <th>surprise</th>\n      <th>sadness</th>\n      <th>disgust</th>\n      <th>joy</th>\n      <th>sentiment_score</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>âš¡The Ukrainian Air Force would like to address...</td>\n      <td>[âš¡, ðŸ‡ºðŸ‡¦, ðŸ§µ]</td>\n      <td>the ukrainian air force would like to address ...</td>\n      <td>air force misinformation media outlets situati...</td>\n      <td>multiple western protectuÐ°sky</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.4404</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>Chernihiv oblast. Ukrainians welcome their lib...</td>\n      <td>[]</td>\n      <td>chernihiv oblast ukrainians welcome their libe...</td>\n      <td>chernihiv oblast liberators standwithukraine s...</td>\n      <td>putinisawarcriminal</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.4588</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>America ðŸ‡ºðŸ‡¸ is preparing for something worse th...</td>\n      <td>[ðŸ‡ºðŸ‡¸, ðŸ‡¹ðŸ‡¼, ðŸ‡·ðŸ‡º, ðŸ‡ºðŸ‡¸, ðŸ‡¨ðŸ‡³, ðŸ‘‡]</td>\n      <td>america is preparing for something worse than ...</td>\n      <td>america something month war policy future rela...</td>\n      <td>worse last new cold best taiwan full</td>\n      <td>[(fear, 0.5015)]</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.4215</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>JUST IN: #Anonymous has hacked &amp;amp; released ...</td>\n      <td>[]</td>\n      <td>just in anonymous has hacked amp released 6200...</td>\n      <td>amp emails marathon group investment firm olig...</td>\n      <td>anonymous eu foreign</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.4019</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>***PUBLIC MINT NOW LIVE***\\n\\nFor \\n@billionai...</td>\n      <td>[]</td>\n      <td>public mint now live for win 100000 during pub...</td>\n      <td>mint sale mint visit information luck nft mint</td>\n      <td>public public further good</td>\n      <td>[(anticipation, 1.0)]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8658</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>The Amazing story of Former Sussex County Dela...</td>\n      <td>[ðŸ‡ºðŸ‡¸]</td>\n      <td>the amazing story of former sussex county dela...</td>\n      <td>story sussex county delaware vance phillips en...</td>\n      <td>amazing former councilman difficult successful...</td>\n      <td>[(fear, 0.4)]</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.9100</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>&amp;amp;quot;How we were waiting for you!&amp;amp;quo...</td>\n      <td>[]</td>\n      <td>ampquothow we were waiting for youampquot in t...</td>\n      <td>ampquothow youampquot region residents defende...</td>\n      <td>chernihiv local novaya chernihiv armed</td>\n      <td>[(anticipation, 0.25), (trust, 0.25), (surpris...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.4939</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>India's purchase of discounted #Russian crude ...</td>\n      <td>[]</td>\n      <td>indias purchase of discounted russian crude oi...</td>\n      <td>purchase crude oil place payment system trade ...</td>\n      <td>indias rupeeruble bilateral western</td>\n      <td>[(trust, 0.6666666666666666)]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.5423</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>The most basic tenet of what stability exists ...</td>\n      <td>[]</td>\n      <td>the most basic tenet of what stability exists ...</td>\n      <td>tenet stability world borders threat use force...</td>\n      <td>basic international</td>\n      <td>[(fear, 0.5), (anger, 0.5)]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.5267</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2022-04-01 00:00:00.000000</td>\n      <td>\"The image that Russia acquired over the past ...</td>\n      <td>[]</td>\n      <td>the image that russia acquired over the past t...</td>\n      <td>image decades putinmedvedev rule power abdÃ¼lme...</td>\n      <td>past global</td>\n      <td>[(fear, 0.2), (anger, 0.2), (anticipation, 0.2...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>-0.5574</td>\n      <td>Negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "tweets_short = tweets[0:10]\n",
    "ed = EmotionDetector()\n",
    "res = ed.process(tweets_short)\n",
    "res.head(100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:01<00:00, 764.27it/s]\n"
     ]
    }
   ],
   "source": [
    "def emotion_analysis(text):\n",
    "    text_object = NRCLex(text)\n",
    "    return pd.Series([' '.join(text_object.words),text_object.affect_list,text_object.top_emotions\n",
    "                      ,text_object.raw_emotion_scores\n",
    "                      ],\n",
    "                     index=['words', 'affect_list', 'top_emotions','scores'])\n",
    "res = tweets_short[\"text\"].progress_apply(emotion_analysis)\n",
    "dataFrame = pd.concat([tweets_short, res], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to extract emoji \n",
      "pre process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56962/56962 [02:15<00:00, 421.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56962/56962 [00:53<00:00, 1055.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56962/56962 [00:26<00:00, 2137.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to extract emoji \n",
      "pre process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50966/50966 [02:14<00:00, 377.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50966/50966 [00:59<00:00, 858.59it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50966/50966 [00:24<00:00, 2096.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to extract emoji \n",
      "pre process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61459/61459 [02:33<00:00, 399.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61459/61459 [01:14<00:00, 826.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61459/61459 [00:31<00:00, 1937.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to extract emoji \n",
      "pre process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56962/56962 [02:22<00:00, 399.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56962/56962 [01:01<00:00, 930.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56962/56962 [00:34<00:00, 1639.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to extract emoji \n",
      "pre process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59960/59960 [01:57<00:00, 508.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59960/59960 [01:05<00:00, 922.30it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59960/59960 [00:26<00:00, 2290.24it/s]\n"
     ]
    }
   ],
   "source": [
    "### Process dataset\n",
    "files = [\"Putin.csv\",\"Russia.csv\",\"Ukraine.csv\",\"Ukraine Russia War.csv\",\"Zelensky.csv\"]\n",
    "#files = [\"Putin.csv\"]\n",
    "ed = EmotionDetector()\n",
    "\n",
    "for file in files:\n",
    "    tweets = pd.read_csv('./data/'+file)\n",
    "    #tweets = tweets[0:1000]\n",
    "    #tweets.set_index(['text'])\n",
    "    tweets = tweets.rename(columns={'0': 'text'})\n",
    "    tweets.head()\n",
    "    tweets.reset_index(drop=True)\n",
    "    res = ed.process(tweets)\n",
    "    res.to_csv('./processed_dataset/'+file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is senseless to shelter Puti\n"
     ]
    }
   ],
   "source": [
    "s= \"rt @TimothyDSnyder: It is senseless to shelter Puti\"\n",
    "s = re.sub(r'(?i)RT @\\w+: ','', s)\n",
    "print(s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}